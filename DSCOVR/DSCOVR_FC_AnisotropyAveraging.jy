################################
#                              #
#     Anisotropy Averaging     #
#                              #
#       Kristoff Paulson       #
#                              #
################################

'''This code combines the two independent measurements of the anisotropy from the DSCOVR_FC_Anisotropy.jy
   script into a single variable. This is done through a weighted average where the weights are given by
   the systematic error values determined via anisotropyCheck.jy.
   Further fitting errors are propagated through to the final product
   
   input:
       L0 cdf created by DSCOVR_FC_Anisotropy.jy
   output:
       L1 cdf containing the variables:
           N_xyz,                                        Unit vector of background magnetic field direction in spacecraft coordinates
           Bmag,                                         Total magnetic field strength
           average_anisotropy,                           Combined anisotropy product
           average_anisotropy_uncertainty_deltaPlus,     Upper uncertainty range of average_anisotropy
           average_anisotropy_uncertainty_deltaMinus,    Lower uncertainty range of average_anisotropy
           beta_SI,                                      Plasma Beta
           beta_parallel_SI,                             Parallel plasma Beta
           beta_perp_SI,                                 Perpendicular plasma Beta

'''




########################

def getTrimDataSet(ds_string,ds_timerange):
    ds = getDataSet(ds_string,ds_timerange)
    ds = trim(ds,ds_timerange)
    
    return(ds)

########################

import sys

tr = getParam('timerange','2017-01-04','Timerange over which to generate combined anisotropy measurement')
version_L0 = getParam('L0Version','0.4.2','Version number of input L0 file')
version_L1 = getParam('L1Version','1.1.2','Version number of output L1 file')

checkForPreviousFiles = getParam('checkPrevious','T','If previous copies of L1 file exist, then skip to next day',['T','F'])
writeStuff = getParam('writeFiles','T','Write out the L1 files with this version of the code?',['T','F'])

if checkForPreviousFiles == 'T':
    checkForPreviousFiles = True
elif checkForPreviousFiles == 'F':
    checkForPreviousFiles = False
    
if writeStuff == 'T':
    writeStuff = True
elif writeStuff == 'F':
    writeStuff = False
    
separatePeaksWithL3Values = getParam('separatePeaksWithL3Values','F','Attempt to calculate anisotropy around each of fit peaks',['T','F'])
    
angleBinWdith = getParam('angleBinWidth',4,'width of bins of incident magnetic field angle in uncertainty maps')
anisotropyBinNumber = getParam('anisotropyBins',40,'Number of bins in anisotropy axis')

analyzingTimeWidthComparisons = False   
fitSeconds = getParam('fitSeconds',1,'Width of time used to fit data for anisotropy (this should only be used in the time comparison results)')

# SI
k    = 1.3807E-23
mu_0 = PI*4E-7
mp   = 1.6726E-27

#######################

try:
    ### IMPORT SUBPROCESSES
    get_OS_version = getFile( 'https://github.com/kpaulson/autoplot/blob/master/CoreSubprocesses/get_os_version.jy',monitor.getSubtaskMonitor('import get_os_version()'))
    execfile( get_OS_version.toString() )
    
    getSPCAnisotropyUncertaintyMaps = getFile( 'https://github.com/kpaulson/autoplot/blob/master/PSPSubProcesses/getSPCAnisotropyUncertaintyMaps.jy',monitor.getSubtaskMonitor('import getSPCAnisotropyUncertaintyMaps()'))
    execfile( getSPCAnisotropyUncertaintyMaps.toString() )
except:
    print 'Unable to grab scripts from github'
    
    
    get_OS_version = getFile( 'C:/Users/kpaulson/Software/Autoplot/GithubScripts/CoreSubprocesses/get_os_version.jy',monitor.getSubtaskMonitor('import get_os_version()'))
    execfile( get_OS_version.toString() )

    getSPCAnisotropyUncertaintyMaps = getFile( 'C:/Users/kpaulson/Software/Autoplot/GithubScripts/PSP/PSPSubProcesses/getSPCAnisotropyUncertaintyMaps.jy',monitor.getSubtaskMonitor('import getSPCAnisotropyUncertaintyMaps()'))
    execfile( getSPCAnisotropyUncertaintyMaps.toString() )


OS = get_os_version().split()[0]

if OS == 'mac':
    googleDrive_directory = 'file:/home/kpaulson/Google Drive File Stream/My Drive/'
elif OS == 'windows':
    googleDrive_directory = 'file:/C:/Users/kpaulson/GoogleDrive/'

#filename = googleDrive_directory+'Research/PSP/SPC/SPC_Anisotropy/Anisotropy_Files/L0/v%s/SPC_Anisotropy_$Y-$m-$d_v%s.cdf'%(version_L0,version_L0)
filename = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/L0/v%s/DSC_Anisotropy_$Y-$m-$d_v%s.cdf'%(version_L0,version_L0)
    
if separatePeaksWithL3Values == 'T':
    separatePeaksWithL3Values = True
elif separatePeaksWithL3Values == 'F':
    separatePeaksWithL3Values = False
if analyzingTimeWidthComparisons == True:
    filename = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/TEMP/L0/v%s/DSC_Anisotropy_$Y-$m-$d_v%s_%ssec.cdf'%(version_L0,version_L0,fitSeconds)

# Create list of VDF poulations over which to perform analysis
vdfList = list() 
if separatePeaksWithL3Values == True:
    vdfList.append('vdf_p1')
    vdfList.append('vdf_3')
    vdfList.append('vdf_a')
else:
    vdfList.append('vdf_full')
    
#This segment should throw an error if the L1 file exists already and is not full of garbage (not the best implementation)
fileAlreadyExists = False
if checkForPreviousFiles == True:
    try:
        if separatePeaksWithL3Values == False:
            if analyzingTimeWidthComparisons == True:
                output_anitostropyL1_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/TEMP/L1/v%s/'%version_L1
                output_anitostropyL1_file = 'DSC_Anisotropy_L1_%s_v%s_%ssec.cdf'%(tr,version_L1,fitSeconds)
            else:
                output_anitostropyL1_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/L1/v%s/'%(version_L1)
                output_anitostropyL1_file = 'DSC_Anisotropy_L1_%s_v%s.cdf'%(tr,version_L1)
            
            TEMP_epoch = getDataSet(output_anitostropyL1_directory+output_anitostropyL1_file+'?Epoch')
            if ne( long(mode(copy(TEMP_epoch))), 0):
                print 'File already exists for %s'%(tr)
                vdfList.remove('vdf_full')
        elif separatePeaksWithL3Values == True:
            for vdf in vdfList:
                output_anitostropyL1_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/L1/v%s/'%(version_L1)
                output_anitostropyL1_file = 'DSC_Anisotropy_%s_%s_v%s.cdf'%(vdf.split('_')[1],tr,version_L1)
                
            TEMP_epoch = getDataSet(output_anitostropyL1_directory+output_anitostropyL1_file+'?Epoch')
            if ne( long(mode(copy(TEMP_epoch))), 0):
                print 'File already exists for %s on %s'%(vdf,tr)
                vdfList.remove(vdf)
                
    except:
        pass
    #fileAlreadyExists = False
    
#if fileAlreadyExists == True:
if eq(len(vdfList),0):
    raise fileAlreadyExistsException
###

for vdf in vdfList:
    if separatePeaksWithL3Values == False:
        anitostropyL0_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/L0/v%s/'%(version_L0)
        filename = anitostropyL0_directory+'DSC_Anisotropy_%s_v%s.cdf'%(tr,version_L0)
    elif separatePeaksWithL3Values == True:
        anitostropyL0_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/L0/v%s/'%(version_L0)
        filename = anitostropyL0_directory+'DSC_Anisotropy_%s_%s_v%s.cdf'%(vdf.split('_')[1],tr,version_L0)
            
    chi = getDataSet(filename+'?Anisotropy_chi',tr)
    chi_plus = getDataSet(filename+'?anisotropy_chi_deltaPlus',tr)
    chi_minus = getDataSet(filename+'?anisotropy_chi_deltaMinus',tr)
    psi = getDataSet(filename+'?Anisotropy_psi',tr)
    psi_plus = getDataSet(filename+'?anisotropy_psi_deltaPlus',tr)
    psi_minus = getDataSet(filename+'?anisotropy_psi_deltaMinus',tr)
    ChiSquared_chi = getDataSet(filename+'?ChiSquared_chi',tr)
    ChiSquared_psi = getDataSet(filename+'?ChiSquared_psi',tr)
    rSquared_chi = getDataSet(filename+'?rSquared_chi',tr)
    rSquared_psi = getDataSet(filename+'?rSquared_psi',tr)
    slopeError_chi = getDataSet(filename+'?slopeError_chi',tr)
    slopeError_psi = getDataSet(filename+'?slopeError_psi',tr)
    standardDev_chi = getDataSet(filename+'?anisotropy_chi_standardDev',tr)
    standardDev_psi = getDataSet(filename+'?anisotropy_psi_standardDev',tr)

    epoch = getDataSet(filename+'?Epoch',tr)

    chi_plus.putProperty(QDataSet.VALID_MIN,0)
    chi_plus.putProperty(QDataSet.VALID_MAX,1E10)
    psi_plus.putProperty(QDataSet.VALID_MIN,0)
    psi_plus.putProperty(QDataSet.VALID_MAX,1E10)
    chi_minus.putProperty(QDataSet.VALID_MIN,0)
    chi_minus.putProperty(QDataSet.VALID_MAX,1E10)
    psi_minus.putProperty(QDataSet.VALID_MIN,0)
    psi_minus.putProperty(QDataSet.VALID_MAX,1E10)
    #chi            = getTrimDataSet(filename+'?Anisotropy_chi',tr)
    #chi_plus       = getTrimDataSet(filename+'?anisotropy_chi_deltaPlus',tr)
    #chi_minus      = getTrimDataSet(filename+'?anisotropy_chi_deltaMinus',tr)
    #ChiSquared_chi = getTrimDataSet(filename+'?ChiSquared_chi',tr)
    #psi            = getTrimDataSet(filename+'?Anisotropy_psi',tr)
    #psi_plus       = getTrimDataSet(filename+'?anisotropy_psi_deltaPlus',tr)
    #psi_minus      = getTrimDataSet(filename+'?anisotropy_psi_deltaMinus',tr)
    #ChiSquared_psi = getTrimDataSet(filename+'?ChiSquared_psi',tr)
    #
    #epoch          = getTrimDataSet(filename+'?Epoch',tr)


    #chi.putProperty(QDataSet.DELTA_PLUS,chi_plus+ChiSquared_chi)
    #chi.putProperty(QDataSet.DELTA_MINUS,chi_minus+ChiSquared_chi)
    #psi.putProperty(QDataSet.DELTA_PLUS,psi_plus+ChiSquared_psi)
    #psi.putProperty(QDataSet.DELTA_MINUS,psi_minus+ChiSquared_psi)
    chi.putProperty(QDataSet.DELTA_PLUS,chi_plus)
    chi.putProperty(QDataSet.DELTA_MINUS,chi_minus)
    psi.putProperty(QDataSet.DELTA_PLUS,psi_plus)
    psi.putProperty(QDataSet.DELTA_MINUS,psi_minus)


    # Recalculate deltaPlus and deltaMinus values since I screwed it up before and it doesn't take long
                                   
    #####
    ##########
    #################

    (anisotropy_deltaPlus,anisotropy_deltaMinus) = getSPCAnisotropyUncertaintyMaps(angleBinWdith,anisotropyBinNumber,OS)
     
    #plot(6,anisotropy_deltaPlus)
    anisotropy_deltaPlus.putProperty(QDataSet.VALID_MIN,0)
    anisotropy_deltaPlus.putProperty(QDataSet.VALID_MAX,1E10)
    anisotropy_deltaMinus.putProperty(QDataSet.VALID_MIN,0)
    anisotropy_deltaMinus.putProperty(QDataSet.VALID_MAX,1E10)
    #################
    ##########
    #####

    try:
        B_hat = getDataSet(filename+'?B_hat',tr)
        Nx = B_hat[:,0]
        Ny = B_hat[:,1]
        Nz = B_hat[:,2]
    except:
        Nx = getDataSet(filename+'?Nx',tr)#print filename
        Ny = getDataSet(filename+'?Ny',tr)#print filename
        Nz = getDataSet(filename+'?Nz',tr)#print filename

    epsilonEpoch = epoch
    anisotropy_chi = chi
    anisotropy_psi = psi
            
    anisotropy_chi_deltaPlus  = dblarr(len(epsilonEpoch))
    anisotropy_chi_deltaMinus = dblarr(len(epsilonEpoch))
    anisotropy_psi_deltaPlus  = dblarr(len(epsilonEpoch))
    anisotropy_psi_deltaMinus = dblarr(len(epsilonEpoch))
    for i in xrange(len(epsilonEpoch)):
        # The asin() is wrong, since I don't want the total orthogonality angle, just the angle between (Nx,Ny) and Nz
        #mappedAngleIndex_chi = imin(abs(toDegrees(asin(Nx[i]))-anisotropy_deltaPlus.property(QDataSet.DEPEND_0))) 
        #mappedAngleIndex_psi = imin(abs(toDegrees(asin(Ny[i]))-anisotropy_deltaPlus.property(QDataSet.DEPEND_0))) 
        
        # This atan() sould account for the above issue
        mappedAngleIndex_chi = imin(abs(toDegrees(atan(Nx[i]/Nz[i]))-anisotropy_deltaPlus.property(QDataSet.DEPEND_0))) 
        mappedAngleIndex_psi = imin(abs(toDegrees(atan(Ny[i]/Nz[i]))-anisotropy_deltaPlus.property(QDataSet.DEPEND_0))) 
        
        mappedAnisotropyIndex_chi = imin(abs(anisotropy_chi[i]-anisotropy_deltaPlus.property(QDataSet.DEPEND_1))) 
        mappedAnisotropyIndex_psi = imin(abs(anisotropy_psi[i]-anisotropy_deltaPlus.property(QDataSet.DEPEND_1))) 
        
        if mappedAngleIndex_chi != -1 and mappedAnisotropyIndex_chi != -1 :
            anisotropy_chi_deltaPlus[i]  = anisotropy_deltaPlus[ mappedAngleIndex_chi,mappedAnisotropyIndex_chi]
            anisotropy_chi_deltaMinus[i] = anisotropy_deltaMinus[mappedAngleIndex_chi,mappedAnisotropyIndex_chi]
        else:
            anisotropy_chi_deltaPlus[i]  = -1
            anisotropy_chi_deltaMinus[i] = -1
            
        if mappedAngleIndex_psi != -1 and mappedAnisotropyIndex_psi != -1 :
            anisotropy_psi_deltaPlus[i]  = anisotropy_deltaPlus[ mappedAngleIndex_psi,mappedAnisotropyIndex_psi]
            anisotropy_psi_deltaMinus[i] = anisotropy_deltaMinus[mappedAngleIndex_psi,mappedAnisotropyIndex_psi]
        else:
            anisotropy_psi_deltaPlus[i]  = -1
            anisotropy_psi_deltaMinus[i] = -1

    chi.putProperty(QDataSet.DELTA_PLUS,anisotropy_chi_deltaPlus)
    chi.putProperty(QDataSet.DELTA_MINUS,anisotropy_chi_deltaMinus)
    psi.putProperty(QDataSet.DELTA_PLUS,anisotropy_psi_deltaPlus)
    psi.putProperty(QDataSet.DELTA_MINUS,anisotropy_psi_deltaMinus)

    chi_plus = anisotropy_chi_deltaPlus
    chi_minus = anisotropy_chi_deltaMinus
    psi_plus = anisotropy_psi_deltaPlus
    psi_minus = anisotropy_psi_deltaMinus

    ############################
    ############################


    ##### Calculate total uncertainty for each measurement
    # This version used the rSquared value, but that uncertainty will decrease for higher slopes, preferentially choosing high anisotropies.
    #chi_deltaMagnitude = sqrt(chi_plus**2 + chi_minus**2) * (1./rSquared_chi)
    #psi_deltaMagnitude = sqrt(psi_plus**2 + psi_minus**2) * (1./rSquared_psi)
    # This version used the ChiSquared value
    #chi_deltaMagnitude = sqrt(chi_plus**2 + chi_minus**2) * (ChiSquared_chi)
    #psi_deltaMagnitude = sqrt(psi_plus**2 + psi_minus**2) * (ChiSquared_psi)
    # Maybe I shouldn't be using that, and instead should keep the ChiSquared separate just to weight the result....
    #chi_deltaMagnitude = sqrt(chi_plus**2 + chi_minus**2)
    #psi_deltaMagnitude = sqrt(psi_plus**2 + psi_minus**2)
    # Or now that I have a "slopeError", I should tack that on to the instrumental error added in quadrature (since they are independent)
    chi_deltaMagnitude = sqrt(chi_plus**2 + chi_minus**2 + standardDev_chi**2)
    psi_deltaMagnitude = sqrt(psi_plus**2 + psi_minus**2 + standardDev_psi**2)

    #plot(0,chi_plus)
    #plot(1,chi_deltaMagnitude)
    #stop

    combined_delta_magnitude = sqrt(chi_deltaMagnitude**2 + psi_deltaMagnitude**2)

    #Theses should be good weights that normalize the two measurements' errors against each other
    inverse_normalized_chi_delta = 1./( chi_deltaMagnitude / combined_delta_magnitude )
    inverse_normalized_psi_delta = 1./( psi_deltaMagnitude / combined_delta_magnitude )


    #inverse_chi_delta =  1./( chi_deltaMagnitude )
    #inverse_psi_delta =  1./( psi_deltaMagnitude )
    #inverse_normalized_chi_delta = sqrt(combined_delta_magnitude**2 + ChiSquared_chi**2 + ChiSquared_psi**2 ) * 1./( chi_deltaMagnitude )
    #inverse_normalized_psi_delta = sqrt(combined_delta_magnitude**2 + ChiSquared_chi**2 + ChiSquared_psi**2 ) * 1./( psi_deltaMagnitude )

    #plot(2,inverse_normalized_psi_delta)


    # This is the original merging of the datasets, but it throws out values where either dataset is fill
    #average_anisotropy = (inverse_normalized_chi_delta*chi + inverse_normalized_psi_delta*psi) / (inverse_normalized_chi_delta + inverse_normalized_psi_delta)
    #average_anisotropy_uncertainty = 2*((inverse_normalized_chi_delta+inverse_normalized_psi_delta)**-2)
    #average_anisotropy.putProperty(QDataSet.DELTA_PLUS,average_anisotropy_uncertainty)
    #average_anisotropy.putProperty(QDataSet.DELTA_MINUS,average_anisotropy_uncertainty)

    # This performs the original merging above, and also uses the single measurements when the other is bad data (fill)
    average_anisotropy = ones(len(epoch))*-1E36
    average_anisotropy_uncertainty = dblarr(len(epoch))
    average_anisotropy_uncertainty_deltaPlus = dblarr(len(epoch))
    average_anisotropy_uncertainty_deltaMinus = dblarr(len(epoch))
    average_anisotropy_fitUncertainty = dblarr(len(epoch))

    chiValidOnly = where(valid(chi).and(eq(valid(psi),0)))
    psiValidOnly = where(valid(psi).and(eq(valid(chi),0)))
    bothValid = where(valid(chi).and(valid(psi)))



    weight_chi = inverse_normalized_chi_delta
    weight_psi = inverse_normalized_chi_delta

    average_anisotropy[bothValid] = (weight_chi[bothValid]*chi[bothValid] + weight_psi[bothValid]*psi[bothValid]) / (weight_chi[bothValid] + weight_psi[bothValid])
    #average_anisotropy[bothValid] = (inverse_normalized_chi_delta[bothValid]*chi[bothValid] + inverse_normalized_psi_delta[bothValid]*psi[bothValid]) / (inverse_normalized_chi_delta[bothValid] + inverse_normalized_psi_delta[bothValid])
    average_anisotropy[chiValidOnly] = chi[chiValidOnly]
    average_anisotropy[psiValidOnly] = psi[psiValidOnly]

    # methodUncertainty is my name for the uncertainty due to the method itself regardless of the data we have (Geometric error?)
    combined_methodUncertainty = sqrt((chi_deltaMagnitude[bothValid]**2+psi_deltaMagnitude[bothValid]**2))/(2)
    combined_methodUncertainty_deltaPlus  = sqrt((chi_plus[bothValid]**2 +psi_plus[bothValid]**2))/(2)
    combined_methodUncertainty_deltaMinus = sqrt((chi_minus[bothValid]**2+psi_minus[bothValid]**2))/(2)

    # This takes the uncertainty due to the difference between chi and psi as a chi-squared error, I don't think this is correct
#    #average_anisotropy_uncertainty[bothValid] = 2*((inverse_normalized_chi_delta[bothValid]+inverse_normalized_psi_delta[bothValid])**-2) + ( ((chi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) + ((psi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) )/2.
#    average_anisotropy_uncertainty[bothValid] = combined_methodUncertainty + ( ((chi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) + ((psi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) )/2.
#    average_anisotropy_uncertainty_deltaPlus[bothValid] = combined_methodUncertainty_deltaPlus + ( ((chi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) + ((psi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) )/2.
#    average_anisotropy_uncertainty_deltaMinus[bothValid] = combined_methodUncertainty_deltaMinus + ( ((chi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) + ((psi[bothValid]-average_anisotropy[bothValid])**2/average_anisotropy[bothValid]) )/2.
#
#    # This takes a simpler approach of delta(x_bar) = (x_1 - x_2) /sqrt(2)   It is probably right
#    #average_anisotropy_uncertainty[bothValid] = 2*((inverse_normalized_chi_delta[bothValid]+inverse_normalized_psi_delta[bothValid])**-2) + ( abs(chi[bothValid]-psi[bothValid])/sqrt(2.) )
#    average_anisotropy_uncertainty[bothValid] = combined_methodUncertainty + ( abs(chi[bothValid]-psi[bothValid])/sqrt(2.) )
#    average_anisotropy_uncertainty_deltaPlus[bothValid]  = sqrt( combined_methodUncertainty_deltaPlus**2  + standardDev_chi[bothValid]**2 + standardDev_psi[bothValid]**2 + abs(chi[bothValid]-psi[bothValid])**2 / 2. )
#    average_anisotropy_uncertainty_deltaMinus[bothValid] = sqrt( combined_methodUncertainty_deltaMinus**2 + standardDev_chi[bothValid]**2 + standardDev_psi[bothValid]**2 + abs(chi[bothValid]-psi[bothValid])**2 / 2. )

    # This takes a simpler approach of delta(x_bar) = (x_1 - x_2) /sqrt(2)   It is probably right
    # Unlike above, this will only be the geometrical error and the uncertainty due to the difference of measurements.
    # The fit uncertainty will only be used in cases where only the chi or psi value is valid as we lose the two-measurement verification
    average_anisotropy_uncertainty[bothValid] = combined_methodUncertainty + ( abs(chi[bothValid]-psi[bothValid])/sqrt(2.) )
    average_anisotropy_uncertainty_deltaPlus[bothValid]  = sqrt( combined_methodUncertainty_deltaPlus**2  + abs(chi[bothValid]-psi[bothValid])**2 / 2. )
    average_anisotropy_uncertainty_deltaMinus[bothValid] = sqrt( combined_methodUncertainty_deltaMinus**2 + abs(chi[bothValid]-psi[bothValid])**2 / 2. )

    # We have additionally added the fit error as a separate variable (partly for transparency, partly because this uncertainty appears to be overly cautious.
    average_anisotropy_fitUncertainty[bothValid] = sqrt(standardDev_chi[bothValid]**2 + standardDev_psi[bothValid]**2)
    average_anisotropy_fitUncertainty[chiValidOnly] = standardDev_chi[chiValidOnly]
    average_anisotropy_fitUncertainty[psiValidOnly] = standardDev_psi[psiValidOnly]

    average_anisotropy_uncertainty[chiValidOnly] = chi_deltaMagnitude[chiValidOnly]
    average_anisotropy_uncertainty_deltaPlus[chiValidOnly] = chi_plus[chiValidOnly]
    average_anisotropy_uncertainty_deltaMinus[chiValidOnly] = chi_minus[chiValidOnly]
    average_anisotropy_uncertainty[psiValidOnly] = psi_deltaMagnitude[psiValidOnly]
    average_anisotropy_uncertainty_deltaPlus[psiValidOnly] = psi_plus[psiValidOnly]
    average_anisotropy_uncertainty_deltaMinus[psiValidOnly] = psi_minus[psiValidOnly]

    average_anisotropy_uncertainty_deltaPlus.putProperty(QDataSet.NAME,'anisotropy_deltaPlus')
    average_anisotropy_uncertainty_deltaPlus.putProperty(QDataSet.TITLE,'Upper range of uncertainty for combined anisotropy measurement')
    average_anisotropy_uncertainty_deltaMinus.putProperty(QDataSet.NAME,'anisotropy_deltaMinus')
    average_anisotropy_uncertainty_deltaMinus.putProperty(QDataSet.TITLE,'Lower range of uncertainty for combined anisotropy measurement')
    
    average_anisotropy_fitUncertainty.putProperty(QDataSet.NAME,'anisotropy_fitUncertainty')
    average_anisotropy_fitUncertainty.putProperty(QDataSet.TITLE,'Standard deviation in the anisotropy measurement due to the fitting portion of the routine')

    average_anisotropy.putProperty(QDataSet.DEPEND_0,epoch)
    average_anisotropy.putProperty(QDataSet.DELTA_PLUS,average_anisotropy_uncertainty_deltaPlus)
    average_anisotropy.putProperty(QDataSet.DELTA_MINUS,average_anisotropy_uncertainty_deltaMinus)
    average_anisotropy.putProperty(QDataSet.VALID_MIN,0)
    average_anisotropy.putProperty(QDataSet.VALID_MAX,1E10)
    average_anisotropy.putProperty(QDataSet.NAME,'anisotropy')
    average_anisotropy.putProperty(QDataSet.TITLE,'DSC ion temperature anisotropy combining independent measurements in Vx/Vz and Vy/Vz planes from L0 v%s file'%(version_L0))

    #average_anisotropy = trim(average_anisotropy,tr)


    r = where(valid(average_anisotropy))
    
    try:
        average_anisotropy_filtered = medianFilter(average_anisotropy[r],10)
    
        average_anisotropy_filtered.putProperty(QDataSet.DEPEND_0,epoch[r])
        average_anisotropy_filtered.putProperty(QDataSet.DELTA_PLUS,average_anisotropy_uncertainty[r])
        average_anisotropy_filtered.putProperty(QDataSet.DELTA_MINUS,average_anisotropy_uncertainty[r])
        average_anisotropy_filtered.putProperty(QDataSet.VALID_MIN,0)
        average_anisotropy_filtered.putProperty(QDataSet.VALID_MAX,1E10)
        #plot(3,average_anisotropy_filtered,ylog=True,yrange=[1E-1,1E1])
    except:
        continue

    load(googleDrive_directory+'Research/PSP/SPC/SPC_Anisotropy/Anisotropy_Files/L1/L1_anisotropyAveragingPlotter.vap')
    #setLayoutOverplot(2)
    plot(0,chi,color='red',legendLabel='&Chi;',ytitle='T!B&perp;!N/T!B||!N',ylog=True,yrange=[1E-1,1E1])
    plot(1,psi,color='blue',legendLabel='&Psi;',ytitle='T!B&perp;!N/T!B||!N',ylog=True,yrange=[1E-1,1E1])
    plot(2,average_anisotropy,ylog=True,yrange=[1E-1,1E1],ytitle='T!B&perp;!N/T!B||!N')

    #plot(3,average_anisotropy_filtered,ylog=True,yrange=[1E-1,1E1])
    #plot(3,epoch,average_anisotropy_uncertainty)

    #STOP

    
#    try:
#        B_sc_1minFile = 'http://research.ssl.berkeley.edu/data/spp/data/sci/fields/staging/l2/mag_SC_1min/$Y/$m/psp_fld_l2_mag_SC_1min_$Y$m$d_v$v.cdf'
#        B_sc = getDataSet(B_sc_1minFile+'?psp_fld_l2_mag_SC_1min',tr)
#        Bmag = magnitude(B_sc)
#        Bmag = synchronize(average_anisotropy,Bmag)
#    except:
#        #N_xyz = getDataSet(filename+'?B_hat',tr)
    if True:
        Bmag = getDataSet(filename+'?B_total',tr)
    
    dscovr_file = 'vap+cdaweb:ds=DSCOVR_H1_FC'
    wp = getDataSet(dscovr_file+'&id=THERMAL_SPD&where=DQF.eq(0)',tr)
    np = getDataSet(dscovr_file+'&id=Np&where=DQF.eq(0)',tr)
    dsc_time = getDataSet(dscovr_file+'&id=Epoch&where=DQF.eq(0)',tr)
    dsc_time.putProperty(QDataSet.VALID_MIN,0)

    sorted_DSC_L3Data = sort(dsc_time)

    wp = wp[sorted_DSC_L3Data]
    np = np[sorted_DSC_L3Data]
    dsc_time = dsc_time[sorted_DSC_L3Data]

    #reset()
    Tp = 0.5*((wp*1E3)**2)*(mp/k)#0.5*(mp/k)**2
    Tp2 = (wp*(9.79E0))**2  # Temperature in K along s/c z-direction

    Tp.putProperty(QDataSet.DEPEND_0,dsc_time)
    np.putProperty(QDataSet.DEPEND_0,dsc_time)
    #Tp = dataset(Tp)
    #np = dataset(np)

    #plot(0,Tp,Tp2)
    #stop

    #B_sc = getDataSet('http://w3sweap.cfa.harvard.edu/data/sci/mag/l2_draft/$Y/$m/psp_fld_l2_mag_$Y$m$d_v$v.cdf?psp_fld_mag_sc',tr)
    #Bmag = magnitude(B_sc)
    #Bmag = synchronize(average_anisotropy,Bmag)

    try:
        downsample_ratio = findex(dsc_time,average_anisotropy.property(QDataSet.DEPEND_0))
        np = interpolate(np,downsample_ratio)
        Tp = interpolate(Tp,downsample_ratio)
    except:
        (np,Tp) = synchronize(average_anisotropy,[np,Tp])

    # ###
    # ### DEFINE T_PARALLEL/T_PERP
    # ###

    theta_Br = acos(Nz)
    #Tp_parallel = Tp / sqrt(1 + average_anisotropy**2)
    Tp_parallel = Tp / (Nz**2 + average_anisotropy*(1 - Nz**2) )
    #Tp_parallel = Tp / ( N_xyz[:,2] + average_anisotropy*sin(acos(N_xyz[:,2])) )
    Tp_perp = Tp_parallel * average_anisotropy
    #Tp_parallel = Tp/(cos^2 theta_BR + a*sin^2 theta_BR)  # Temperature in K

    # From Mike:
    #I get that the parallel and perpendicular components of the temperature, once you solve for T_R and anisotropy factor a, are as follows:

    #Tpar = T_R/(cos^2 theta_BR + a*sin^2 theta_BR)
    #Tperp =  a*Tpar



    # ###
    # ### CALCULATE BETA
    # ###

    ## cgs.. off from SI by a constant factor of 1.0827310778 -> what the hell is this factor?
    #k    = 1.3807E-16
    #mu_0 = 1.
    #pressureParticle = (np)*k*(Tp*8.6174E-5)#nkT
    #pressureParticle = (np)*k*(Tp*13.606)#nkT
    #pressureMag = (Bmag*1E-5)**2/(2*mu_0)
    #beta_cgs = pressureParticle/pressureMag

    # SI
    #k    = 1.3807E-23
    #mu_0 = PI*4E-7
    pressureParticle = (np*1E6)*k*(Tp)#nkT
    pressureParticle_parallel = (np*1E6)*k*(Tp_parallel)#nkT
    pressureParticle_perp = (np*1E6)*k*(Tp_perp)#nkT
    pressureMag = (Bmag*1E-9)**2/(2*mu_0)

    beta_SI = pressureParticle/pressureMag
    beta_SI.putProperty(QDataSet.VALID_MIN,1E-10)
    beta_SI.putProperty(QDataSet.VALID_MAX,1E10)
    beta_SI.putProperty(QDataSet.NAME,'Beta')
    beta_SI.putProperty(QDataSet.LABEL,'&beta;')
    beta_SI.putProperty(QDataSet.TITLE,'Ion Plasma Beta from DSC Moments')

    beta_parallel_SI = pressureParticle_parallel/pressureMag
    beta_parallel_SI.putProperty(QDataSet.VALID_MIN,1E-10)
    beta_parallel_SI.putProperty(QDataSet.VALID_MAX,1E10)
    beta_parallel_SI.putProperty(QDataSet.NAME,'Beta_parallel')
    beta_parallel_SI.putProperty(QDataSet.LABEL,'&beta;!B||')
    beta_parallel_SI.putProperty(QDataSet.TITLE,'Ion Plasma Parallel Beta from DSC Moments')

    beta_perp_SI = pressureParticle_perp/pressureMag
    beta_perp_SI.putProperty(QDataSet.VALID_MIN,1E-10)
    beta_perp_SI.putProperty(QDataSet.VALID_MAX,1E10)
    beta_perp_SI.putProperty(QDataSet.NAME,'Beta_perp')
    beta_perp_SI.putProperty(QDataSet.LABEL,'&beta;!B&perp;')
    beta_perp_SI.putProperty(QDataSet.TITLE,'Ion Plasma Perpendicular Beta from DSC Moments')

    ## NRL Formulary.. same as SI
    #beta_NRL = (4.03E-11)*(np)*(Tp*8.6174E-5)*((Bmag*1E-5)**-2)
    
    # THIS WHOLE SECTION IS ONLY ON SPC, SHOULDN'T APPLY TO DSC
    #    dqf = getDataSet(sweap_directory+sweap_file+'?DQF',tr)
    #    dqfEpoch = dqf.property(QDataSet.DEPEND_0)
    #
    #    s = sort(dqfEpoch)
    #    dqf = dqf[s,:]
    #    dqfEpoch = dqfEpoch[s]
    #
    #    peakOffScaleHigh = dqf[:,11]
    #    peakOffScaleLow = dqf[:,12]
    #
    #    peakOffScale = ones(len(dqf))
    #    r = where(eq(peakOffScaleHigh,0).and(eq(peakOffScaleLow,0)))
    #    peakOffScale[r] = 0.
    #    peakOffScale.putProperty(QDataSet.DEPEND_0,dqfEpoch)
    #
    #    try:
    #        peakOffScale_L1Cadence = synchronize(average_anisotropy,peakOffScale)
    #    except:
    #        dqf_to_anisotropy_ratio = findex(dqfEpoch,epsilonEpoch)
    #        peakOffScale_L1Cadence = interpolate(peakOffScale_L1Cadence,dqf_to_anisotropy_ratio)
    #    peakOffScale_L1Cadence = round(peakOffScale_L1Cadence,0)
    #
    #    peakOffScale_L1Cadence.putProperty(QDataSet.NAME,'WindSpeedOffScale_flag')
    #    peakOffScale_L1Cadence.putProperty(QDataSet.LABEL,'Wind Speed Off Scale')
    #    peakOffScale_L1Cadence.putProperty(QDataSet.TITLE,'Flag indicating DSC bulk wind speed is below or above detectable range (0=good, 1=bad))')


    #average_anisotropy.putProperty(QDataSet.DELTA_PLUS,None)
    #average_anisotropy.putProperty(QDataSet.DELTA_MINUS,None)

    anisotropyMin = 0.1
    anisotropyMax = 10
    anisotropyBinNumber = 50
    betaMin = 0.0001
    betaMax = 10000
    betaBinNumber = 140

    aa = logspace(anisotropyMin,anisotropyMax,anisotropyBinNumber)
    bb = logspace(betaMin,betaMax,betaBinNumber)

    rebin_anisotropyVsBeta = rebin( link(beta_parallel_SI,average_anisotropy,ones(len(average_anisotropy))) , bb , aa )

    #plot(3,beta_cgs/beta_SI)
    plot(3,beta_SI)
    plot(4,beta_parallel_SI)
    plot(5,beta_perp_SI,xrange=tr)
    #plot(4,(B_parallel*1E-9)**2/(2*mu_0))
    #plot(3,beta_parallel_SI,average_anisotropy,renderType='scatter',ylog=True,xlog=True,ytitle='T!B&perp;!N/T!B||!N',xtitle='&beta;!B||')
    #plot(3,((4.03E-11)*(np)*(Tp*8.6174E-5)*((Bmag*1E-5)**-2))/beta_SI)

    #average_anisotropy.putProperty(QDataSet.DELTA_MINUS,None)
    #average_anisotropy.putProperty(QDataSet.DELTA_PLUS,None)
    #plot(6,average_anisotropy,(beta_perp_SI/beta_parallel_SI))

    plot(6,rebin_anisotropyVsBeta.property(QDataSet.WEIGHTS),zlog=True,ylog=True,yrange=[1E-1,1E1])



    ###
    ###
    ###

    if writeStuff == True:
        if separatePeaksWithL3Values == False:
            if analyzingTimeWidthComparisons == True:
                output_anitostropyL1_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/TEMP/L1/v%s/'%version_L1
                output_anitostropyL1_file = 'DSC_Anisotropy_L1_%s_v%s_%ssec.cdf'%(tr,version_L1,fitSeconds)
            else:
                output_anitostropyL1_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/L1/v%s/'%(version_L1)
                output_anitostropyL1_file = 'DSC_Anisotropy_L1_%s_v%s.cdf'%(tr,version_L1)
        elif separatePeaksWithL3Values == True:
            output_anitostropyL1_directory = googleDrive_directory+'Research/DSCOVR/Anisotropy/Anisotropy_Files/L1/v%s/'%(version_L1)
            output_anitostropyL1_file = 'DSC_Anisotropy_L1_%s_%s_v%s.cdf'%(vdf.split('_')[1],tr,version_L1)
        
        if 'B_hat' in locals():
            formatDataSet(B_hat,                                     output_anitostropyL1_directory + output_anitostropyL1_file)
            formatDataSet(Bmag,                                      output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            formatDataSet(average_anisotropy,                        output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            formatDataSet(average_anisotropy_uncertainty_deltaPlus,  output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            formatDataSet(average_anisotropy_uncertainty_deltaMinus, output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            formatDataSet(average_anisotropy_fitUncertainty,         output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            formatDataSet(beta_SI,                                   output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            formatDataSet(beta_parallel_SI,                          output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            formatDataSet(beta_perp_SI,                              output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
            #formatDataSet(peakOffScale_L1Cadence,                    output_anitostropyL1_directory + output_anitostropyL1_file+'?append=T')
        else:
            bindle = bundle(Nx, Ny, Nz, Bmag)
            bindle = bundle(bindle, average_anisotropy, average_anisotropy_uncertainty_deltaPlus, average_anisotropy_uncertainty_deltaMinus)
            bindle = bundle(bindle, average_anisotropy_fitUncertainty)
            bindle = bundle(bindle, beta_SI, beta_parallel_SI, beta_perp_SI)
            #bindle = bundle(bindle, peakOffScale_L1Cadence)
            bindle.putProperty(QDataSet.DEPEND_0,epsilonEpoch)
            
            formatDataSet(bindle, output_anitostropyL1_directory + output_anitostropyL1_file + '?bundle=T')
